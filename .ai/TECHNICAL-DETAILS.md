
# Implementation Plan

## Architecture Overview

**System Architecture:** The solution will follow a **modular, service-oriented architecture** with the following components:

- **Data Ingestion Service:** A backend module that **queries on-chain EAS attestations** and feeds them into the database. This will likely run as a scheduled job or background worker within the API service. It will call the EAS GraphQL endpoints for each supported chain to fetch new or updated attestations. *Rationale:* EAS provides a convenient GraphQL API for each network’s attestation data ([Gitcoin: EAS Attestation Explorer
](https://checker.gitcoin.co/public/project/show/eas-attestation-explorer#:~:text=Additionally%2C%20the%20EAS%20Explorer%20provides,attestation%20data%20across%20several%20chains)), so we can avoid writing low-level blockchain listeners. The ingestion will maintain a checkpoint (like last fetched block or timestamp per chain) to fetch only new attestations incrementally.
- **Database (Supabase/Postgres):** A centralized storage of all location proof attestations. This will have tables reflecting the attestation schema. Likely a primary table `location_proofs` with columns: `uid` (attestation UID, primary key), `chain` (network identifier), `prover` (address of the prover, from EAS `from` field), `subject` (subject address or ID), `timestamp` (block timestamp or attestation time), `event_timestamp` (the claimed event time, from attestation data) ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=Timestamp%20Time%20the%20location%20proof,Depends%20on%20the)), `srs` (spatial reference system, e.g. "EPSG:4326"), `location_type` (e.g. "DecimalDegrees<string>" or other) ([Location Types | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/location-types#:~:text=Initially%2C%20location%20proofs%20will%20use,longitude%2C%20latitude)), `location` (the raw location string, e.g. `"[lon, lat]"`), parsed numeric `longitude` and `latitude` (for convenience), `recipe_types` (array of proof recipe identifiers), `recipe_payloads` (array of payload blobs, likely stored as bytea or base64 text), `media_types` (array of attached media types), `media_data` (array of media data strings, e.g. IPFS CIDs), `memo` (text note), and `blockchain_timestamp` (the time the attestation was recorded on-chain, if different from event time). We will also include a boolean or separate table for `revocations` if an attestation can be revoked, or at least a flag if the attestation is currently valid. The database design will build on the existing AstralProtocol models to ensure consistency with prior work.
- **REST API (OGC Features):** An HTTP API built perhaps with Node.js/TypeScript (Express or Fastify) or a Python framework – but Node/TS is likely since Apollo is Node. This API will expose endpoints conforming to OGC API Features. We will likely use an Express.js server where certain routes serve OGC data and Apollo Server is integrated for GraphQL on a different route (e.g. `/graphql`). The REST endpoints will fetch data from the database (via an ORM or query builder) and format it as GeoJSON Features. Each location proof in the database becomes a GeoJSON Feature with a geometry and properties. For example, for proofs using WGS84 coordinates, the geometry will be a `Point` with the [longitude, latitude] from the attestation. Other location types (like geohash or plus codes) might be translated to a geometry or stored as properties if not directly convertible. The REST API will implement all required OGC routes: 
  - **Landing Page:** `GET /` – returns API title/description and links (in JSON and HTML) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=Resource%20Method%20Path%20Purpose%20Landing,are%20offered%20through%20the%20API)).
  - **Conformance:** `GET /conformance` – returns a list of OGC API standards implemented (at least the URI for Features Core 1.0, and likely CRS and Filtering if we include those).
  - **Collections:** `GET /collections` – returns metadata about available collections. We might define one collection per data set. Here, we have to decide how to model collections: likely one collection for “LocationProofs” as a whole. Alternatively, we could present each blockchain as a separate collection (e.g. `proofs_arbitrum`, `proofs_celo`, etc.), or each location proof *type* as separate collections. Given the schema is uniform across chains, a single collection of all proofs is simplest. We can include a property for `chain` in each feature. So `/collections` will list one collection (or a few) with descriptive info.
  - **Collection Info:** `GET /collections/{collectionId}` – details about the "LocationProofs" collection (e.g. description, CRS supported which will be WGS84, and the list of available properties and sample values).
  - **Features:** `GET /collections/{collectionId}/items` – this is the core data access: returns a paginated list of location proof features in GeoJSON format. We will implement query parameters here for filtering: `bbox` (bounding box in WGS84) to restrict results by location, `datetime` to filter by event time or attestation time (we need to decide which; likely by event time since that’s the subject of the proof, but possibly both). Using PostGIS in the database will allow efficient spatial filtering by bbox ([PostGIS: Geo queries | Supabase Docs](https://supabase.com/docs/guides/database/extensions/postgis#:~:text=PostGIS%3A%20Geo%20queries%20,location%2C%20get%20data%20within)) (we’ll store a geometry column for location). We will also allow `limit`/`offset` or OGC’s `limit`/`next` links for paging. Initially, attribute-based filtering (like by prover address or recipeType) may not be directly exposed via query params unless we implement OGC Filtering Part 3 fully. Instead, such queries can be done via GraphQL. However, we will design the code such that adding filter parameters (e.g. `prover=0xabc…`) later is straightforward.
  - **Feature by ID:** `GET /collections/{collectionId}/items/{featureId}` – returns a single location proof by its unique ID. The `featureId` in our case could be the attestation UID (a 32-byte hex string). We will allow clients to retrieve a specific proof by UID via this endpoint.
  
  All responses will follow OGC API schema and include the required linking and structure. For example, the Feature Collection response will include `links` (to self, next page, etc.) and each Feature will include at least an `id`, `geometry`, `properties`, and possibly `links` to related resources (like a link to the raw attestation on EASScan or to media). **GeoJSON** will be the default encoding for items (when `f=json` or no format specified) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=Note%20that%20the%20response%20to,is%20HTML%20in%20this%20case)). We will ensure the JSON keys and structure match the OGC examples so that any OGC client can parse it.

- **GraphQL API (Apollo Server):** Running in the same server (or separate if needed) will be an Apollo GraphQL server. Apollo Server will be set up to use our database as the data source. We will define a GraphQL schema (SDL) that mirrors the data model of location proofs – e.g. types like `LocationProof` with fields corresponding to the attestation (id, chain, prover, location (with subfields or as a custom scalar for geometry), eventTimestamp, etc.). We will include any relationships if relevant (for instance, if we had users or other entities, but at this point, mostly flat data). The Apollo server’s **resolvers** will fetch from the database. We can use a library like Prisma or an ORM for easy querying, or query directly with SQL using a pool. The GraphQL will allow queries such as:
  ```graphql
  query {
    proofs(filter: { chain: "Arbitrum", bbox: [minLon,minLat,maxLon,maxLat], timeframe: { from: "...", to: "..." } }) {
      id
      prover
      location { latitude, longitude }
      eventTimestamp
      recipeType
    }
  }
  ```
  as an example. We might implement filtering arguments for chain, prover address, time range, location bounding box, etc. If complex filtering is needed, we can either implement it in the GraphQL layer or rely on direct DB queries (Apollo can integrate with Postgres via data sources or we can call a stored procedure). The GraphQL API will enable clients to request only specific fields (e.g. just id and location) to save bandwidth, which is a strength of GraphQL ([GraphQL Architecture & Big Picture](https://www.howtographql.com/basics/3-big-picture/#:~:text=,a%20connected%20database)). We will also set up Apollo’s playground or use GraphiQL for easy querying in development, and possibly Apollo Studio for schema publishing (since this is an internal API, that’s optional).
  
  Using Apollo ensures we are using a **spec-compliant GraphQL server** that is production-ready ([Introduction to Apollo Server - Apollo GraphQL Docs](https://www.apollographql.com/docs/apollo-server#:~:text=Apollo%20Server%20is%20an%20open,use%20data%20from%20any%20source)). Apollo also supports features like caching, rate limiting, and even federation if we later split services. In this implementation, Apollo will act as a **proxy** in the sense that it doesn’t have its own separate database – it pulls from the same Supabase DB that the REST API uses (ensuring consistency between REST and GraphQL responses).

- **Supabase Services:** Apart from the database, we will enable **PostGIS** on the Supabase database for geo queries, and configure a publication for the `location_proofs` table to enable Realtime (Postgres Changes feed) ([Realtime | Supabase Docs](https://supabase.com/docs/guides/realtime#:~:text=,send%20them%20to%20authorized%20clients)). The API server can subscribe to this feed if needed (e.g., to push updates via WebSockets or server-sent events to OGC clients – though OGC API doesn’t define push, we might provide a custom WS endpoint). More importantly, front-end clients could use the Supabase JS client to subscribe directly to new proofs (if building a dashboard). For authentication, we will initialize Supabase Auth (email/password or OAuth if needed) so that if in the future we have write operations (like a user marking something), we can secure it. In this phase, authentication might not be heavily used since reading public proofs is open, but the infrastructure will be in place.

- **Infrastructure and Deployment:** The entire application (data ingestion + REST + GraphQL) will be containerized in a Docker image. For local development, we’ll use **Docker Compose** with (1) the API container, (2) a Postgres container (with PostGIS, simulating Supabase locally), and optionally (3) a pgadmin or test client container. This allows any contributor to quickly run the stack. In the cloud, we can deploy the API container to a service like AWS ECS, Azure Container Apps, or a Heroku/Render-like service. The database in production will be the Supabase cloud instance (managed Postgres). We will not run our own Postgres in production to keep ops simple and benefit from Supabase's scaling and managed backups. The API container will connect to the Supabase DB via the provided connection string (secured via env var).

- **External Integrations:** The key external integration is the **EAS GraphQL API** for fetching attestations. We will maintain configuration for each supported chain, including the GraphQL endpoint URL (e.g. `https://sepolia.easscan.org/graphql` for Sepolia, etc.) and the schema UID to filter by ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=the%20v0,across%20all%20chains)). The ingestion service will query these. We might use the EAS TypeScript SDK if available, or just direct GraphQL queries (using `node-fetch` or Apollo client). The GraphQL query will ask for attestation fields according to the schema (which likely returns the packed data or already decoded fields if EAS indexer knows the schema). If not fully decoded, we might get a bytes blob that we need to decode manually. Given the EAS schema is known, we can decode the bytes for `recipePayload` etc., but often EAS GraphQL will return the data in structured form if the schema is registered (to be verified during implementation). We'll handle whichever the case, decoding as needed to store meaningful values.

**Module Organization:** We will organize the codebase so that each concern is separated (following an MVC or clean architecture style):
- Models/Entities: Definitions of the data structures (could be Prisma models or Sequelize models, or simple TypeScript interfaces plus Zod schemas for validation).
- Services: e.g. `EasFetcher` service that knows how to query EAS GraphQL, `DatabaseService` for writing/reading proofs (or just use ORM directly).
- Controllers/Resolvers: For REST, controllers handle HTTP requests and call Services/DB. For GraphQL, resolvers serve a similar role, but we can reuse service logic to avoid duplication.
- A separate directory (or even package) for OGC compliance specifics – e.g. formatting responses, building the conformance document, etc. We might create utility functions to generate the JSON response for each endpoint (to ensure we include all required fields like links, etc.).
- .ai or docs folder: We will keep **design docs** (like this plan, PRD, etc.) in the repo (much like the `.ai` folder in the existing repo) to track high-level decisions. This helps future contributors understand the architecture and reasoning, fulfilling the "reusable and easily enhanced" goal.

## Data Ingestion Workflow

**Fetching Attestations:** We will implement a robust workflow to keep the database in sync with on-chain events:
1. **Initial Backfill:** On first run, the service will fetch all existing attestations for the known schema on each chain. EAS GraphQL allows querying by schema UID, possibly with pagination. We’ll use queries like:
   ```graphql
   query GetProofs($schema: ID!, $lastID: String) {
     attestations(schema: $schema, first: 1000, after: $lastID) {
       edges { node { id uid timeData data … } pageInfo { endCursor hasNextPage } }
     }
   }
   ```
   (The exact query structure may differ; we’ll refer to EAS docs for correct fields). We will loop through pages until all are fetched, and store them in the DB.
2. **Regular Updates:** After initial data is seeded, the service will periodically poll each GraphQL endpoint for new entries. We might use a timestamp filter if supported (e.g. “attestations created after X time”) or just fetch the latest N and compare with last stored UID. Another approach is to use EAS event webhooks or a pub/sub if available, but GraphQL polling is simplest initially. We can run this polling on an interval (say every minute) or even set up a **Supabase Edge Function** or cron (Supabase has a scheduling for functions) to trigger the fetch. However, running it as part of our API container (a cron job thread) is fine for now.
3. **On New Attestation:** When a new attestation is found, the service will decode its fields and upsert into the database. Decoding includes parsing the `location` string. Since v0.1 uses `"DecimalDegrees<string>"` with format `"[lon, lat]"` ([Location Types | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/location-types#:~:text=Initially%2C%20location%20proofs%20will%20use,longitude%2C%20latitude)), we can parse the string (JSON parse to get an array of two numbers). We’ll store those numbers in separate `longitude` and `latitude` columns (and construct a PostGIS `geometry(Point)` from them). If `locationType` is something else, we handle accordingly (for now, likely all are the same type). `recipePayload` which is bytes – we might store as base64 text if small, or just keep the reference if too complex. The key is to make sure all relevant info is queryable: e.g., if `recipeType` contains multiple entries, perhaps store them in a JSONB column or a separate join table if we want normalization (depends on query needs; likely JSONB array is fine).
4. **Reorgs and Duplicates:** On chains, blocks could reorganize, but since attestations are on finality or at least eventually final, duplicates should not appear. We use the unique UID as primary key – if we see an attestation that already exists, we skip or update if any data changed (the data shouldn’t change except revocation status).
5. **Revocations:** If EAS supports revocation (the original attester can revoke an attestation), we must capture that. EAS GraphQL likely has a field or a separate query for revoked attestations. We will include a step to check for revocations (perhaps periodically check if any attestation in our DB is marked revoked by EAS). Alternatively, subscribe to revocation events if EAS provides them. Implementation: Add a boolean `revoked` field to the DB. The ingestion service can call a `attestation(uid)` query to see if it exists or is revoked on-chain. If revoked, mark accordingly or remove if we decide not to show revoked ones. We will expose `revoked` status in the API (and possibly by default filter them out of active queries unless a client explicitly asks).
6. **Continuous Operation:** This ingestion can run as a loop. We will implement it carefully to avoid heavy load: e.g., use **exponential backoff** or a sleep if nothing new is found, and ensure we do not hit rate limits of the EAS GraphQL APIs. The EAS GraphQL endpoints are read-heavy but we assume moderate usage. We might integrate a simple caching for GraphQL results (though for new data, not much caching can be done).
7. **Error Handling:** If a fetch fails (network issue or EAS API down), the system should log it and retry later, without crashing the whole API. We will separate the ingestion process so it doesn’t block serving existing data. Possibly run it in a different thread or process, or simply handle exceptions so that the web server continues running.

By structuring ingestion this way, **the database becomes the single source of truth** for the API, allowing fast queries and join operations which wouldn’t be possible by querying the blockchain directly per request. This trade-off (some latency for data freshness) is acceptable since proofs don’t need to appear the instant they are on-chain (a short delay is fine for our use cases). If real-time is needed, one could always query EAS directly, but our service focuses on aggregated queries.

## OGC API Features Compliance

We will adhere to **OGC API - Features 1.0.1 Core** compliance in the API design and responses. Key implementation details to ensure compliance:

- **Endpoint Structure:** As listed earlier, we will implement all the core endpoints in the standard paths ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=Resource%20Method%20Path%20Purpose%20Landing,are%20offered%20through%20the%20API)) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=Feature%20collection%20GET%20%2Fcollections%2F,is%20identified%20in%20the%20path)). We will also host an **OpenAPI definition** (the OGC API definition) at `/api` or via a link from the landing page. OGC API suggests that the OpenAPI document either be available at `/api` or a `service-desc` link. We can generate this OpenAPI (possibly by customizing the official OGC example to our specifics) and serve it as static JSON. This allows clients to programmatically discover our API capabilities.

- **Landing Page:** This will return a JSON (and HTML if `Accept: text/html`) with title "Astral Protocol Location Proof API", description, and links to `collections`, `conformance`, and `api` definition. We will follow the example from OGC API documentation for formatting these links (using proper `rel` types: `self`, `service-doc`, `service-desc`, `conformance`, `data`) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=Landing%20page)) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=The%20link%20to%20the%20Conformance,link%20relation%20type)).

- **Conformance:** We will list at least the URNs of OGC API Features Core and likely the GeoJSON requirement class. For example, include `https://api.stacspec.org/v1.0.0-beta.3/core` (if needed for STAC) or the OGC Features core URN `http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core`. (We will double-check the exact identifiers from OGC API Features standard). Since we might support `bbox` and `datetime`, we should also list the `conf/geojson` and `conf/filter` conformance classes if applicable ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=A%20bbox%20or%20datetime%20parameter,net%2Fdar)).

- **Collections:** The output will contain an array of collections. If we use a single collection for all proofs, it will have an `id` like "location-proofs", a title, a description (e.g. "Location Proof attestations from multiple blockchains"), a time extent (the min and max event timestamps present, as per OGC API recommendation for temporal extent), and a spatial extent (the bounding box of all data). We can compute these extents from the DB (with queries: MIN and MAX of event time, and overall spatial envelope of all points). This metadata helps clients know the data coverage. Also include links for each collection (to its items and to itself).

- **Items (Features):** When returning feature data, we must follow **GeoJSON FeatureCollection** format for the items list. Each feature in `features[]` will have:
  - `"id": "<attestation UID>"`
  - `"geometry": { "type": "Point", "coordinates": [lon, lat] }` (for WGS84 points; if locationType differs, we might have to adjust. If, say, location was a geohash string, ideally we convert to a geometry (center of geohash cell or polygon). Initially, since all are decimal degrees coordinates, geometry is straightforward.)
  - `"properties": { ... }` containing the non-spatial attributes. We will include fields like `chain`, `prover`, `subject`, `eventTimestamp`, `locationType`, `recipeType` (possibly as array), `media` (maybe combine mediaType and mediaData for readability), `memo`, etc. We might exclude extremely verbose or binary data from properties for performance (or include a summary). However, OGC API does not forbid binary, but GeoJSON standard says properties should be serializable. If `recipePayload` is binary data not meaningful to most clients, we might omit it or provide it as base64 string in properties. This is a design decision: since our API is primarily for reading, including base64 blobs might be okay. Alternatively, we include a link for detail per feature where the GraphQL or another endpoint could give full details. We will likely include most fields in properties for completeness, except maybe we mark some as optional if they bloat the response.
  - `"time"` or `"datetime"`: OGC Features has an optional `"time"` property at feature or uses a standard name in properties for time. We can include the event time as the feature’s time. Possibly we can use the `properties.timestamp` and `properties.eventTimestamp` to distinguish recorded time vs event time.

- **Filtering and Query Parameters:** To achieve “full compliance,” core only mandates basics (which doesn’t include filtering by attributes in the standard). However, spatial (`bbox`) and temporal (`datetime`) filters are commonly included (they might technically be part of the Features standard or an extension). We will implement:
  - `bbox=minLon,minLat,maxLon,maxLat` query parameter on the items endpoint, to return only features within that bounding box ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=A%20bbox%20or%20datetime%20parameter,net%2Fdar)). Our DB query will use the geometry column and PostGIS `&&` or `ST_Within` to filter.
  - `datetime` parameter on items: ISO8601 time or time range (e.g. `2025-01-01T00:00:00Z/2025-01-31T23:59:59Z`). We will filter eventTimestamp (or maybe the attestation blockchain time) by that range. OGC API defines that `datetime` can be a single time or a range separated by `/`. We’ll parse that and apply a SQL WHERE on the timestamp.
  - We will consider supporting an `offset` and `limit` or the OGC specified paging (usually OGC uses `limit` and provides a link with `next` that has a token for the next page). We might do simplest: require the client to use `limit` & `offset` (which is not official OGC, but the standard says the API should declare how paging works – it can be done via next links, which we can implement by using the last feature ID or so). To keep compliance, perhaps implement the `next` link approach: we’ll return at most `limit` (default maybe 100) features, and if more remain, include a `links: [ { rel: "next", href: "...?offset=100" } ]`. This is a slight hybrid but acceptable. Strictly, OGC core allows any approach as long as explained in API definition.
  
- **Validation:** To ensure compliance, we will test our API with the OGC Validator test suite for Features ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=)). This suite will call our endpoints and verify structure. Part of our CI could eventually run these tests (they are available as a Docker image or a web service). This will catch any deviations from the spec early. For example, ensuring content types are correct (GeoJSON uses `application/geo+json` typically), required fields are present, etc.

By implementing the above, any application that understands OGC API Features will be able to navigate from our landing page to the collection and retrieve features. This opens the door for interoperability – e.g., a QGIS user could add our API as a vector layer by just pointing to the `/collections/{id}/items?f=json` endpoint, or a web map could easily overlay proofs.

## GraphQL API Implementation

The GraphQL API will be built with **Apollo Server (Node.js)**. Key steps and details:

- **Schema Definition:** We will write a GraphQL schema (`schema.graphql` file) that defines types such as:
  ```graphql
  type LocationProof {
    uid: ID!
    chain: String!
    prover: String!
    subject: String
    eventTimestamp: String!
    location: Location!    # a custom type for spatial data
    locationType: String!
    srs: String!
    recipeType: [String!]!
    recipePayload: [String!]!  # or perhaps a custom scalar for bytes
    mediaType: [String!]!
    mediaData: [String!]!
    memo: String
    timestamp: String!      # chain attestation timestamp
    revoked: Boolean
  }
  type Location {
    latitude: Float
    longitude: Float
    geohash: String
    # (we can accommodate multiple location representations if needed)
  }
  type Query {
    locationProof(uid: ID!): LocationProof
    locationProofs(filter: ProofFilter, limit: Int, offset: Int): [LocationProof!]!
  }
  input ProofFilter {
    chain: String
    prover: String
    fromDate: String
    toDate: String
    withinBBox: [Float!]    # [minLon,minLat,maxLon,maxLat]
  }
  ```
  This is an example – we will refine it with actual needs. The idea is to allow flexible filtering. We might also add connections for pagination (instead of raw array, use `LocationProofConnection` type with pageInfo). But for simplicity, an array with limit/offset is okay to start. 

- **Resolvers and Data Access:** We will implement resolvers in Apollo: 
  - `Query.locationProofs`: reads the `filter` input and constructs a DB query accordingly. For example, if `filter.chain` is provided, add `WHERE chain = ...`. If `filter.withinBBox` is provided, use a SQL function to filter the geometry. We can leverage an ORM or query builder for this. Using something like Knex or Prisma would allow us to build queries in TypeScript safely. Prisma could map the PostGIS geometry to a custom type, but might be simpler to execute raw SQL for spatial queries. We will aim to keep this logic in a separate service module (e.g., `ProofService.findAll(filter)`), which returns an array of proof objects. The resolver then returns that. If no filter, returning all proofs might be too heavy, so we will encourage at least some filtering or a small default limit.
  - `Query.locationProof`: straightforward lookup by UID (primary key in DB).
  - Field resolvers are mostly not needed if we return complete objects. But if we define `Location` as a sub-object, our service could either return `latitude` & `longitude` as part of the proof object (and Apollo can nest it automatically if shaped properly) or we provide a resolver for `LocationProof.location` that takes the stored lat/long and wraps in the `Location` type.
  
  The Apollo server will run in **schema-first** mode (using the SDL above) and we’ll use code generation or types for TypeScript to ensure type-safety. The Apollo library will handle translating GraphQL queries to calling our resolvers.

- **Apollo Configuration:** We will set up Apollo with CORS allowed for our front-end domains, and disable introspection in production if desired (to prevent schema leaking to randoms, though it’s public data so it’s not sensitive). We will enable Apollo’s built-in Playground only in non-production environments for debugging. Apollo v4 is the latest (as of 2025) which we’ll use ([Introduction to Apollo Server - Apollo GraphQL Docs](https://www.apollographql.com/docs/apollo-server#:~:text=Apollo%20Server)).

- **GraphQL Proxy Concept:** The GraphQL will essentially serve as an **alternative interface** to the same data that the OGC REST endpoints provide. In some cases, the GraphQL might even call the same internal functions as the REST. For example, we might implement a function to get proofs by bbox that is used by both the REST `/items` handler and the GraphQL resolver for `withinBBox`. This avoids duplicate logic. We can ensure consistency (so that a given query via REST or GraphQL yields the same results if the parameters are equivalent).

- **Testing GraphQL:** We will write unit tests for resolvers (maybe using Apollo’s testing utilities or just calling the service functions). Also, we will test some example queries against a test database to ensure the results and performance.

- **Advanced GraphQL Features:** While not required on day one, we design with future enhancements in mind:
  - **Subscriptions:** Apollo could allow GraphQL subscriptions so clients can get real-time updates over WebSockets. We can integrate this with Supabase Realtime. For example, on new row insert in `location_proofs`, our server (or a Supabase function) could publish to a PubSub engine that Apollo listens to. Apollo supports subscription using a pub-sub mechanism (like Redis or in-memory). For a simpler approach, Apollo Server can integrate with Supabase’s socket: The client could directly use Supabase’s subscription, but a unified GraphQL subscription like `subscription { newProofs { uid, location { ... } ... } }` would be elegant. Implementation could be: when the ingestion adds a row, trigger a NOTIFY on Postgres which our server listens to (via PG LISTEN) and then pushes to subscribed GraphQL clients. This might be added later, but our architecture will leave room (perhaps by abstracting the insertion so we can hook in a publish event).
  - **Schema Evolution:** If the attestation schema evolves (v0.2 with new fields), GraphQL schema can be extended with new fields (which is non-breaking for clients if we only add). Our code will be structured to handle extra fields (e.g. if a new `altitude` field appears, we add column and expose it easily).
  - **Apollo Federation (if needed):** In future, if we have separate services (say a separate service for user profiles or for spatial zone data), we could federate them into one graph. Right now, not needed, but using Apollo means we could adopt federation later without a complete rewrite.

In summary, the GraphQL API will provide a **flexible, self-documenting interface** (GraphQL’s schema serves as documentation). Developers can query exactly what they need, reducing over-fetching compared to the fixed REST endpoints ([GraphQL Architecture & Big Picture](https://www.howtographql.com/basics/3-big-picture/#:~:text=,a%20connected%20database)). By using Apollo, we align with best practices (“the best way to build a production-ready, self-documenting GraphQL API” ([Introduction to Apollo Server - Apollo GraphQL Docs](https://www.apollographql.com/docs/apollo-server#:~:text=Apollo%20Server%20is%20an%20open,use%20data%20from%20any%20source))). It also complements the OGC API: for integrations where standard geo interfaces are needed, use OGC; for custom app development, use GraphQL.

## Database Design and Supabase Usage

The database is central to our implementation. We will use **Supabase (Postgres)** for both development and production (possibly the free tier to start, then scaling up as needed). Key aspects of the database implementation:

- **Schema Implementation:** As mentioned, the main table `location_proofs` (name tentative) will contain columns corresponding to the EAS schema fields ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=structured.,Specified%20in%20recipe%20definition)) ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=definition.%60mediaType%20%60%60string,User%20input)). We will also include surrogate keys or indexes as needed. Likely the attestation UID (which is a 32-byte hex string) can serve as the primary key (text or UUID type). We will index important query fields: e.g., an index on `chain` (to quickly filter by network), an index on `prover`, an index on `eventTimestamp` (for sorting or time filtering), and a **GIS index** on the geometry (PostGIS `GIST` index for spatial queries) ([PostGIS: Geo queries | Supabase Docs](https://supabase.com/docs/guides/database/extensions/postgis#:~:text=PostGIS%3A%20Geo%20queries%20,location%2C%20get%20data%20within)). These indexes ensure queries remain fast as data grows.
- **Spatial Data:** We will use PostGIS for geometry. When inserting a proof, we take the latitude/longitude and do `ST_SetSRID(ST_MakePoint(lon, lat), 4326)`. This allows using all the spatial functions (bbox queries, distance calculations, etc.). We can also use PostGIS to compute the overall extent or other analysis if needed by the API.
- **JSON Fields:** Some attestation components like `recipeType` (string array) and `recipePayload` (bytes array) might not be used for filtering often. We can store them as JSONB or text. JSONB could be good if later we want to query “proofs of a certain recipeType”. Similarly, `mediaType` and `mediaData` arrays can be JSONB. We should ensure these fields are flexible to accommodate multiple values (since the schema allows multiple proof recipes per attestation ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=Proof%20Recipe%20Identifier%20Indicates%20the,of%20supported%20media%20types%2C%20to))). If needed, we could even break out a related table for recipes (one-to-many with proof ID) but that might complicate queries for little benefit right now.
- **Supabase Configuration:** 
  - We will enable Row Level Security (RLS) on the table but start with a policy that allows read access to all (if we want the REST API to be publicly accessible without auth). Alternatively, we might skip RLS and instead not expose the DB directly (since our API mediates access). For safety, enabling RLS and using a Supabase service role (with a secret key) for our API is a good practice – meaning our API will authenticate to the DB with full rights, but any other access is locked down.
  - We will create a publication for the `location_proofs` table’s INSERT, UPDATE, DELETE events so that Supabase Realtime can broadcast them ([Realtime | Supabase Docs](https://supabase.com/docs/guides/realtime#:~:text=By%20default%20Realtime%20is%20disabled,table)) ([Realtime | Supabase Docs](https://supabase.com/docs/guides/realtime#:~:text=From%20the%20client%2C%20we%20can,table)). This just requires a quick setup in the Supabase dashboard or via SQL (`CREATE PUBLICATION ...`). With this, any client with Supabase SDK can do:
    ```js
    supabase.channel('any').on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'location_proofs' }, payload => { ... }).subscribe();
    ```
    and get new proof notifications. This is extremely useful for front-end maps that want live updates.
  - We will use Supabase Storage (if needed) for any binary large data. For example, if in future we want to fetch the actual media (like photos) for a proof, we might store them in Supabase Storage (which is an S3 under the hood) and keep only URLs or references in `mediaData`. For now, `mediaData` likely holds IPFS CIDs which the client can fetch from IPFS, so we don't need to store actual media content.
  - **Authentication & Authorization:** If in the future some proofs need access control (unlikely, since they are public on-chain), we could restrict the API. But more realistically, if we add user-specific data (like user accounts linking to their proofs, or allowing users to annotate proofs), Supabase Auth (with JWTs and RLS policies) will be leveraged ([Auth | Supabase Docs](https://supabase.com/docs/guides/auth#:~:text=Auth%20,RLS%29)). For example, a policy could allow each user to only modify their own annotations. At this time, our main data is public, so we focus on secure read access. We will ensure the database credentials and service role keys are kept secure (not exposed in client-side code, only in server).
  - **Performance on Supabase:** Supabase provides some metrics; we will monitor the size of the table and query performance. If needed, we’ll add caching at the API layer for heavy endpoints (e.g., cache the last full GeoJSON response for a certain area if that’s hit often, using an in-memory cache like Redis or even Apollo’s response cache).
  
- **Existing Database Design Integration:** The existing AstralProtocol/api repository’s `app/models` likely already define some of these structures (perhaps in an ORM models or SQL migrations). We will **reuse and adapt** those definitions. For instance, if there's a `LocationProof` model class with attributes for each schema field, we'll port that into our project (possibly as a Prisma schema or Sequelize model). This ensures continuity with any other Astral tools relying on the same DB. If that model included constraints or default values, we’ll preserve them. We’ll also review the `.ai/implementation-plan.md` in the repo for any specific decisions about the DB (e.g., naming conventions, planned normalization) and ensure our plan aligns with it.

- **Data Volume and Retention:** Initially, the number of proofs will be manageable (maybe hundreds or thousands). But we should anticipate growth if Astral Protocol becomes popular. The DB should handle millions of rows. Postgres can, especially with proper indexing. We may consider table partitioning by year or by chain if it grows very large (to improve query performance per segment), but that might be premature. However, designing the schema with potential partitioning in mind (for example, including a `chain` column that could be a partition key) is wise. Supabase (Postgres 15 under the hood) does support partitioning, but we likely won't need to implement it until far into the future, if ever.
  
- **Backup and Recovery:** Supabase automatically backups data, but we will still set up a way to reconstruct data from chain if needed (since the chain is the ultimate source of truth). In a disaster scenario where the DB is lost and backups fail, we could re-run the ingestion from genesis to rebuild state (that might take time, but it’s possible). Having that as a fallback is comforting, though we will rely on Supabase’s managed backups for quick recovery.

In essence, the database will act as a **cache and index** of on-chain proofs optimized for querying. Using Supabase gives us real-time and auth capabilities out-of-the-box, which we will integrate where beneficial. By carefully indexing and using PostGIS, we ensure the geospatial queries (which are central to this API’s purpose) are efficient.

## Automated Workflows and CI/CD

To achieve a highly automated, low-maintenance project, we will enforce **DevOps best practices** from the start. Key elements of our CI/CD and workflow:

- **Version Control & Branch Strategy:** All code will live in a Git repository (likely the existing AstralProtocol/api repo). We will use a branching strategy where `main` (or `master`) is the stable branch that triggers deployments. Feature development happens in branches, which are merged via Pull Requests. We will require PR reviews and passing tests before merge, protecting the main branch from broken code.

- **Continuous Integration (CI):** Set up GitHub Actions (or an equivalent CI platform) to run on every push and PR. CI tasks include:
  - **Install Dependencies:** For Node, install npm packages; also set up services like Postgres for tests (using a service container in GH Actions or a lightweight SQLite if tests can run with that).
  - **Linting/Formatting:** Run ESLint and Prettier to enforce code style. This keeps the codebase clean and consistent.
  - **Type Checking:** If using TypeScript, run `tsc --noEmit` to catch type errors.
  - **Unit Tests:** Execute all unit and integration tests. We will write tests for critical functions (e.g., decoding logic, the OGC output format, GraphQL resolvers). For database-dependent tests, we can use a test DB (the CI can spin up a Postgres container and our tests can apply migrations and run).
  - **Coverage & Quality Gates:** Optionally, measure test coverage and fail the build if below a threshold (to encourage thorough testing).

  By enforcing these in CI, we ensure every commit maintains quality. *Implementing CI/CD best practices like committing frequently, maintaining stable builds, and streamlining tests is crucial to reliability ([Best Practices for Awesome CI/CD](https://www.harness.io/blog/best-practices-for-awesome-ci-cd#:~:text=Implementing%20CI%2FCD%20best%20practices%2C%20such,value%20to%20customers%20more%20quickly)).* This reduces bugs and regressions, ultimately speeding up our delivery.

- **Continuous Delivery/Deployment (CD):** We will automate deployment so that once code is merged to main (and passes CI), it gets deployed to our staging or production environment:
  - We can use GitHub Actions to build the Docker image (with a tag, e.g., the commit SHA or a version number) and push to a registry (Docker Hub or AWS ECR).
  - Then, either the action triggers a deploy (e.g., calling our server hosting to pull the new image) or we use a platform that auto-deploys on image push. For example, if using a service like Fly.io or Heroku (container deployment), we integrate with it. If using AWS ECS, we might need to run a task update via AWS CLI in the action.
  - Infrastructure-as-Code will play a role: we can have Terraform scripts that define our production infrastructure (DB on Supabase, an ECS service or a Kubernetes deployment for the API, etc.). These can be applied manually when infra changes, but day-to-day deploys just replace the app version.
  - We will also set up a **staging environment** (perhaps a separate Supabase project and a container deployed to a staging server) to test new features in a production-like setting before promoting. This can be deployed from a “develop” branch or on every PR (ephemeral environments). Supabase makes it easy to branch the database or use a copy for testing, if needed.

- **Testing Workflows:** Beyond unit tests, we plan integration tests that spin up the whole system. Using Docker Compose, we can start the API and a test DB, then run a test script that calls the REST and GraphQL endpoints (simulating a client). This can verify, for example, that hitting `/collections/location-proofs/items?bbox=...` returns the expected filtered results. We can populate the test DB with known values for these tests. These integration tests could run in CI as well (though they are slower) or at least in a nightly build.

- **Agentic Development Principles:** We will adopt an *agentic approach* to development where tasks are broken into smaller, automatable units and the system can, to some extent, **run itself or adapt**. In practice, this means:
  - Embracing Infrastructure as Code so environments are reproducible without manual steps (the "agent" here is the IaC tool applying changes).
  - Using bots/automation for mundane tasks: e.g., a dependency update bot for keeping libraries up to date, an automated changelog generator from commit messages, etc.
  - Possibly incorporating AI assistance (as hinted by "agentic") for code generation or testing. For instance, using GPT-based code review tools or test case generators in the workflow (if allowed). This is more experimental, but since the `.ai` folder exists, the team is open to AI involvement. We can integrate something like a CI job that uses a language model to analyze the code for certain vulnerabilities or documentation gaps (with caution).
  - Automated workflows also include monitoring: we can set up alerts (PagerDuty or just Slack notifications) for when something fails (CI failure, or production error). This reduces the need for constant human oversight.

- **Docker and Dev Environment:** All developers should be able to run `docker compose up` and get a fully running API with a local Postgres. We will provide seed data or scripts to load some sample attestations (maybe from Sepolia testnet) for immediate testing. Documentation will be provided in the README for how to run, how to run tests, etc. This lowers the onboarding effort for new contributors.
  - We’ll also have a one-command initialization (maybe using Supabase CLI to start a local Supabase, which under the hood uses Docker, so either way works).
  - Dockerfile will be written for a production build (minimized image, using multi-stage to build and then run a slim production image with just node and the compiled JS, if TS is used). We’ll ensure it uses environment variables for all secrets so that we can deploy easily by injecting those (Supabase URL, keys, etc.).
  - If needed, Docker Compose can also emulate multiple services (if we had a separate worker for ingestion, for example, we could scale that out in compose too). But likely one service that handles both API and background jobs is fine (perhaps using something like BullMQ for scheduling, or a simple `setInterval` in Node).

- **Infrastructure as Code:** 
  - For the **Supabase setup**, we can treat it partly as code by writing SQL migration scripts. Supabase provides a migrations folder where all schema changes are recorded as SQL files. We will use that: any table or index we create will be through the Supabase CLI (`supabase db push` which generates a migration). These SQL migrations will be checked into the repo, so the DB schema is version-controlled. If someone sets up the project anew, applying all migrations will get the correct schema.
  - For cloud infrastructure beyond the DB: if using AWS, we’ll create Terraform for the ECS cluster, task definitions, load balancer, etc. If using a simpler PaaS, we might not need heavy IaC, but we will at least script the configuration (like writing a `docker-compose.prod.yml` for deploying, or a GitHub Actions deploy job).
  - The idea is any team member or even an automated agent can recreate or migrate the environment easily using these codified steps, ensuring consistency across dev/staging/prod.

- **Best Practices Adherence:** We will continuously incorporate current best practices (as of 2025) into the pipeline. For example:
  - Use **semantic versioning** and possibly tagging releases in Git, so deployments can be rolled back to a known version if needed.
  - Keep dependencies updated to patch security issues (monitor via Dependabot or similar).
  - Implement security scanning of the Docker image (CI can use a tool to scan for vulnerabilities in base images or libs).
  - Performance testing: potentially have a job that runs a small load test on staging to catch any performance regression.
  - Documentation: auto-deploy documentation from the repo (if we use Docusaurus or just markdown in the repo, ensure it’s up to date). Possibly enforce that the OpenAPI spec is up to date with the code (maybe via tests).
  
With these automated workflows, the project can **evolve with minimal manual effort**. New features can be added by following the established patterns (update schema, write migration, write code, write tests, CI verifies, deploy). If everything is scripted, even scaling up (like moving to a bigger DB instance, or adding a new network) can be done in a controlled, repeatable way.

## Best Practices and Technologies (2025)

In building this API, we will leverage **best practices as of March 2025** in API development, cloud architecture, and software engineering:

- **API Design:** We abide by proven design standards for both REST and GraphQL. By implementing OGC API standards, we ensure our REST design is not bespoke but rather aligned with an industry standard ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=OGC%20API%20,are%20specified%20in%20additional%20parts)). This means better interoperability and less reinventing the wheel. For GraphQL, we follow the Apollo recommendations for schema design (e.g. use plural field names for lists, use proper nullability, etc.) and avoid anti-patterns like huge query types without pagination. We also implement careful error handling: REST errors will follow HTTP status codes and problem+JSON structure; GraphQL errors will include meaningful messages without exposing internal stack traces.

- **Scalability & Performance:** We will design for **horizontal scalability**. The API stateless components (REST/GraphQL) can be scaled by running multiple containers behind a load balancer. The database (Supabase) vertically scales or in future may allow read replicas. To keep costs low initially, we might run a single instance, but the code will not hold state that prevents multi-instance use. Caching strategies will be used where appropriate: e.g., enable HTTP caching on GET endpoints (with ETags or Last-Modified headers based on the latest data timestamp) so that clients or CDNs can cache responses. Internally, for repetitive chain queries, we could cache recently fetched attestation IDs to avoid reprocessing them. We will also consider using a simple in-memory cache for GraphQL resolvers if the same query repeats frequently. Another best practice is to use **DataLoader** pattern in GraphQL (batching DB requests), though our queries are straightforward enough that we might not need it immediately.

- **Security:** Even though data is public, we will secure the system following best practices. This includes using HTTPS everywhere (we'll ensure SSL on the endpoints), enabling CORS only for allowed origins or making it restrictive if possible, and sanitizing all inputs to prevent injection (our use of parameterized queries or ORM will handle SQL injection concerns, and GraphQL queries are validated against the schema). We'll also monitor dependencies for vulnerabilities and patch promptly. The GraphQL endpoint will have depth limiting or query complexity limiting to prevent abuse (GraphQL can be abused with deeply nested queries – Apollo provides plugins to limit query depth/complexity).

- **Logging and Monitoring:** We'll include structured logging in the API (each request logged with method, path, response time, etc.). In production, these logs can go to a service like Datadog or CloudWatch for analysis. We’ll set up basic monitoring: uptime checks and possibly performance metrics (p99 latency, etc.). Best practice is to have an **observability** stack so we can detect issues early. We might containerize a lightweight monitoring or at least use Supabase’s monitoring for the DB (they have performance insights).

- **Documentation and Developer Experience:** We'll maintain clear docs. The OpenAPI spec (for OGC) and the GraphQL schema (which can be introspected and perhaps we publish a GraphQL schema docs site) serve as reference. We will also include a README and a docs site (maybe on docs.astral.global) for this API specifically – explaining usage with examples (how to do a query for proofs in area X via REST vs GraphQL). As of 2025, having an interactive API explorer is considered best practice; we can deploy Swagger UI for the OGC endpoints and GraphQL Playground for GraphQL for developers to try out calls. Ensuring the API is easy to use is key to adoption.

- **Privacy and Compliance:** Though not directly asked, we should note any PII (personally identifiable info) concerns. Location proofs might indirectly reveal user movement. However, all data here is on-chain and opt-in by users. We will still include a privacy consideration in docs. From a compliance standpoint, since we’re dealing with location data, we ensure to follow any relevant guidelines (for example, GDPR if any EU personal data – but an Ethereum address and coordinates likely aren’t personal data by themselves, still worth caution).

- **Enhancement and Maintenance:** We follow a modular architecture so new features can be added with minimal changes. For example, adding a new blockchain: just add config and possibly a new migration if we want to tag the chain (or just use the same table with chain field). Adding a new OGC collection: possibly just configure and reuse the same underlying data. The code is written in a clear, idiomatic style (using TypeScript types, making use of modern ES features like async/await, etc.). We will also keep an eye on emerging tech – e.g., by 2025, there might be new tools for GraphQL caching or new Postgres extensions; we remain flexible to integrate those if beneficial.

- **Cost Management:** Best practices in 2025 also emphasize cost-effectiveness. We will monitor resource usage (CPU/memory of the container, DB load). Using managed services (Supabase) is cost-effective up to a point (avoid hiring DBA, etc.). We’ll use Supabase’s free tier for development and a paid tier for production as needed. The stateless API can initially run on a small VM or free container hosting (if available), then scale out. We should utilize serverless options if they significantly cut cost – e.g., deploying the GraphQL API as a Vercel serverless function could scale to zero on no traffic. However, OGC endpoints might fit better in a persistent service (serverless cold starts might add latency). We will evaluate a hybrid: maybe deploy on a low-cost VM and auto-scale as needed. Also, by consolidating everything into one service (rather than microservices) for now, we reduce overhead costs (one container to manage). This monolithic approach is fine given the scope and aligns with cost-saving by having fewer moving parts.

- **Community and Contribution:** Since Astral is likely open source, we will manage the project on GitHub with open issue tracking, encourage contributions, and use standards like Conventional Commits for clarity. A CONTRIBUTING.md will outline how to run tests, how to add a feature. Automated checks (like lint) give quick feedback to contributors.

By following these best practices, we ensure the API is not only functional, but **robust, secure, and maintainable**. The landscape of tech in 2025 encourages using high-level managed platforms and focusing on core business logic; we embody that by using Apollo, Supabase, and open standards instead of reinventing wheels.

## Scalability and Cost Considerations

**Scalability Strategy:** From the outset, the API is designed to scale both in terms of **read throughput** (number of queries) and **data volume** (growing attestations). Here’s how we address scalability:

- **Stateless Horizontal Scaling:** We can run multiple instances of the API behind a load balancer to handle concurrent requests. Both the OGC REST and GraphQL endpoints are read-heavy and stateless (writes only happen in the ingestion process, which we can also replicate or partition by chain). This means scaling out is straightforward. For example, we might run 3 replicas of the API container to handle high load. Apollo Server and our Express handlers do not store session data (any needed caching is either in-memory per instance or in the DB/Redis if we add one), so a load balancer can distribute requests arbitrarily.

- **Database Scaling:** The Supabase Postgres can be scaled vertically to a larger instance if queries become slow. Postgres can handle quite large datasets on a single node with proper indexing. If one node becomes insufficient for read traffic, Supabase (or vanilla Postgres) supports read replicas. We could direct heavy read-only queries (perhaps from GraphQL which might get many per second) to a replica, while writes (ingestion) go to the primary. However, this introduces complexity (ensuring replicas are up-to-date for queries – eventual consistency delay might be fine for non-real-time data). We likely won’t need replicas until we have tens of millions of rows or hundreds of QPS. Another aspect is partitioning: we could horizontally partition data by chain or time (e.g., one logical database per chain). But to keep cost low, we prefer one database with indexing rather than multiple smaller ones which add overhead.

- **Caching Layers:** To reduce direct load on the DB, we will implement caching where feasible. REST endpoints can leverage HTTP caching: we’ll include `ETag` or a `Last-Modified` based on the newest attestation timestamp in the response. Clients or CDNs can then cache the response for short periods. For instance, a query for all proofs in January 2025 can be cached and reused if repeated soon. We might deploy a CDN in front of the OGC endpoints if there are heavy repeated spatial queries (though many queries will be unique by bbox). As a future improvement, we could pre-tile the data (like generate geojson tiles) but that's beyond initial scope. For GraphQL, caching is trickier (as each query can be different), but Apollo Client on the frontend typically caches results. On the server, we might cache certain frequent queries results in memory. Apollo also supports **persisted queries** to save on parsing overhead if needed ([Introduction to Apollo Server - Apollo GraphQL Docs](https://www.apollographql.com/docs/apollo-server#:~:text=Build%20and%20run%20queries%20,29Integration%20testing%20%2031)).

- **Ingestion Scaling:** As the number of supported blockchains grows, the ingestion service must scale or adjust. If we add many chains, polling them serially might become too slow (miss data or cause delays). We can scale ingestion by multi-threading or splitting by chain. For example, have one worker thread per chain querying in parallel. This might increase memory/CPU usage but ensures timely updates. In a more advanced setup, we could use a message queue (like a job for each chain, and multiple worker instances). Initially, a single process can handle a few chains easily with periodic polling.

- **Coping with Data Growth:** If location proofs become very popular (imagine thousands per day), our system must handle a large influx. The database insertion rate with indexing should be fine for moderate rates (hundreds per second). If it grew to thousands per second, we’d need to consider batching inserts or using a buffering system. Perhaps the EAS GraphQL itself would be a bottleneck in that case. We can monitor and adjust the polling frequency. Also, if data is huge, queries by broad filters (e.g., get all proofs ever) become heavy. But typically, clients will narrow by time or area. We will enforce sensible defaults (like if no filter, only return last 100 proofs to avoid accidentally dumping the entire DB).

- **Cost Management:** We want to keep costs low, especially early on. Our choices reflect this:
  - Using **Supabase**: it has a free tier for development and affordable plans. It offloads maintenance. If we used our own Postgres on cloud, we’d have to manage backups etc., which is overhead. Supabase also gives the realtime and auth features integrated (saving us building those).
  - **Container Hosting**: We will likely use a cloud provider that offers a low-cost container runtime. If traffic is low at start, we might run on a single small VM (like $5-$10/month range). As usage grows, we can move to auto-scaling infrastructure, but only pay for what we use. 
  - **On-Demand Scaling**: If we anticipate spiky usage, we could integrate with serverless tech. For example, we might put the GraphQL resolvers behind an AWS Lambda if each query can be handled quickly – Lambdas scale to zero cost when idle. However, OGC REST serving static files might not fit Lambda as well (though it could). A compromise is using something like AWS Fargate with auto-scaling, so when idle it runs minimal, and scales out on demand.
  - **Monitoring Costs**: We will monitor Supabase storage and egress. If our API gets used heavily, egress (data transfer) might cost. We could mitigate by enabling gzip compression on responses to cut bandwidth (especially for GeoJSON which can compress well). Also ensure we don’t fetch unnecessarily large data from EAS (only fetch needed fields to reduce their egress and our ingress).
  - **Optimize Queries**: To avoid needing overly powerful hardware, we optimize at the software level. Complex computations (if any) should be done in SQL or in memory efficiently. For example, computing spatial filters is done by PostGIS C code (fast). We will avoid N+1 query problems in GraphQL by batching where possible. Efficient code means we can run on smaller instances.

- **Graceful Degradation:** If certain parts become too costly to maintain at scale, we design fallback options. E.g., if Supabase real-time turns out too expensive (charging per socket maybe), we could disable it and only use polling on client side for updates. Or if storing all historical proofs becomes costly but most use-cases only need recent data, we could archive older data to cold storage (and remove from primary DB) after a period, re-querying from chain on demand for older ones. These are strategies to reduce storage costs long-term.

- **Testing for Scale:** We will do load tests to ensure the system can handle expected load before going live. E.g., simulate X clients querying a popular endpoint concurrently and see if response times are acceptable and how the DB performs. We should also test scaling the ingestion by simulating a burst of new proofs and seeing if the system ingests and makes them available without lag.

In conclusion, the architecture is cloud-ready and can scale vertically and horizontally without fundamental changes. We purposely use robust technologies (Postgres, Apollo) known to handle scale. By monitoring and incrementally scaling, we can support growing usage while keeping the **cost proportional to actual demand**. Initially, the costs will be low due to low usage; as it ramps up, the additional users or use-cases will justify the incremental cost. This pay-as-you-grow model ensures we are not over-provisioned at the start, yet we have a clear path to grow when needed.

---

**Conclusion:** This implementation plan lays out a comprehensive approach to building the Astral Protocol API as a production-grade system. It covers the product requirements, system design, and practical steps leveraging modern best practices and automation. By integrating existing Astral Protocol work and focusing on standards compliance, the API will be immediately useful and interoperable. Through CI/CD and careful planning, enhancements in the future (supporting new proof types, more blockchains, or new query capabilities) can be added with minimal friction, allowing Astral’s location-proof ecosystem to evolve and scale confidently. 

**Sources:**

- Astral Protocol Location Proof Schema and Docs ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=the%20v0,across%20all%20chains)) ([EAS Schema | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/eas-schema#:~:text=structured.,Specified%20in%20recipe%20definition)) ([Location Types | Astral Documentation](https://docs.astral.global/docs/location-proof-protocol/location-types#:~:text=Initially%2C%20location%20proofs%20will%20use,longitude%2C%20latitude))  
- OGC API Features Standard (Core concepts and endpoints) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=OGC%20API%20,are%20specified%20in%20additional%20parts)) ([OGC API - Features - OGC API workshop](https://ogcapi-workshop.ogc.org/api-deep-dive/features/#:~:text=Resource%20Method%20Path%20Purpose%20Landing,are%20offered%20through%20the%20API))  
- EAS (Ethereum Attestation Service) and GraphQL API info ([Gitcoin: EAS Attestation Explorer
](https://checker.gitcoin.co/public/project/show/eas-attestation-explorer#:~:text=Additionally%2C%20the%20EAS%20Explorer%20provides,attestation%20data%20across%20several%20chains)) ([Speedrun EAS - Ethereum Attestation Service](https://docs.attest.org/docs/quick--start/quickstart#:~:text=Just%20type%20%2Fgraphql%20at%20the,org%2F%20%C2%B7%20https%3A%2F%2F))  
- Apollo GraphQL Server Best Practices ([Introduction to Apollo Server - Apollo GraphQL Docs](https://www.apollographql.com/docs/apollo-server#:~:text=Apollo%20Server%20is%20an%20open,use%20data%20from%20any%20source))  
- Supabase Features (PostGIS for geo, Realtime for DB changes) ([PostGIS: Geo queries | Supabase Docs](https://supabase.com/docs/guides/database/extensions/postgis#:~:text=PostGIS%3A%20Geo%20queries%20,location%2C%20get%20data%20within)) ([Realtime | Supabase Docs](https://supabase.com/docs/guides/realtime#:~:text=,send%20them%20to%20authorized%20clients))  
- CI/CD and DevOps Best Practices ([Best Practices for Awesome CI/CD](https://www.harness.io/blog/best-practices-for-awesome-ci-cd#:~:text=Implementing%20CI%2FCD%20best%20practices%2C%20such,value%20to%20customers%20more%20quickly))  
- GraphQL Architecture Concepts ([GraphQL Architecture & Big Picture](https://www.howtographql.com/basics/3-big-picture/#:~:text=,a%20connected%20database))  
